{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import hamming, euclidean\n",
    "from scipy.stats import pearsonr\n",
    "import hashlib\n",
    "import ctypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#words 170 ['10', '19', '2021', '668', '9bhydkxz8u', 'ability', 'actual', 'admitted', 'advantage', 'aff', 'africa', 'against', 'airway', 'allisonpearson', 'and', 'anothe', 'antiviral', 'anyone', 'application', 'are', 'aren', 'as', 'asterhealthcare', 'babies', 'be', 'breakthrough', 'but', 'by', 'can', 'cases', 'caused', 'child', 'cihr', 'cihr_irsc', 'closing', 'co', 'continue', 'corrected', 'course', 'covid', 'covid19', 'cross', 'data', 'de', 'deis85208721', 'delta', 'did', 'die', 'disruptions', 'drcchambers', 'drmroz', 'edfuw5qjah', 'effect', 'enemyinastate', 'enhance', 'erictopol', 'evade', 'evades', 'everyone', 'extending', 'eyes', 'fail', 'far', 'freethinkfacts', 'from', 'get', 'going', 'had', 'has', 'hav', 'high', 'how', 'https', 'hyper', 'immune', 'immunity', 'impact', 'in', 'inasmuch', 'induced', 'infection', 'is', 'it', 'its', 'ivermectin', 'japan', 'kowa', 'light', 'load', 'london', 'lsoril', 'manifest', 'many', 'maxdkozlov', 'may', 'mdfacep', 'melulater', 'might', 'milde', 'mkky24weqv', 'mutations', 'nabs', 'not', 'november', 'of', 'older', 'omicron', 'on', 'only', 'our', 'over', 'people', 'peterandann', 'pompey1977', 'prevent', 'produced', 'protection', 'quicker', 'recent', 'registration', 'reinfection', 'related', 'reported', 'research', 'results', 'review', 'rt', 'says', 'sealsoftheend', 'showed', 'shown', 'so', 'south', 'spreads', 'stevebennett15', 'studies', 'sufficient', 'suggest', 'surge', 'svictor70973566', 'system', 'taken', 'that', 'the', 'their', 'they', 'thinks', 'this', 'thus', 'to', 'toddlers', 'together', 'transmissible', 'upper', 'vaccine', 'vaccines', 'variant', 'veoqyz5x6f', 'versa', 'vice', 'viral', 'want', 'was', 'wasohope', 'who', 'why', 'widespread', 'wildantlers', 'working', 'yaneerbaryam']\n"
     ]
    }
   ],
   "source": [
    "#corpus: 15 tweets using Omicron as the query (Jan 32, 2022)\n",
    "corpus = [\"DrCChambers RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"sealsoftheend Japan's Kowa says Ivermectin showed 'antiviral effect' against Omicron https://t.co/mKKY24WeQV\",\n",
    "\"SVictor70973566 RT @EricTopol: Why is Omicron so hyper-transmissible? It's not related to high viral load in the upper airway, as shown by 2 recent studies…\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Actual cases of reinfection by Omicron are so widespread they are manifest to anyone who is not closing their eyes: 10/…\",\n",
    "\"lsoril RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"pompey1977 RT @AllisonPearson: How can people not get it? Omicron’s advantage over Delta is it evades the vaccine. Everyone is going to get Omicron…\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Taken together, our results suggest that Omicron-induced immunity may not be sufficient to prevent infection from anothe…\",\n",
    "\"SteveBennett15 RT @EricTopol: Anyone who thinks that vaccines aren't working against Omicron might want to review the data https://t.co/9bHYdKxz8u https:/…\",\n",
    "\"wasohope RT @ASTERHealthcare: Omicron covid-19 variant was reported from South Africa on November 2021. This variant has had many mutations that aff…\",\n",
    "\"SVictor70973566 RT @MdFacep: @EricTopol @maxdkozlov Omicron's impact is in its ability to evade our immune system: Our 'older' vaccine produced NABS fail…\",\n",
    "\"Wildantlers @melulater Of course it did, Omicron spreads far quicker. But as a % of people who die from omicron it is far milde… https://t.co/eDFuW5qjAH\",\n",
    "\"peterandann RT @EnemyInAState: Omicron, London: Babies and toddlers continue to surge, and 1 in 9 admitted is a child. Over 668 babies and toddlers hav…\",\n",
    "\"DrMroz RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"Deis85208721 CORRECTED-Japan's Kowa says ivermectin showed 'antiviral effect' against Omicron in research https://t.co/VEoQyz5x6F\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Thus, breakthrough infection from Omicron may enhance cross-protection against Delta, and vice-versa, [only] inasmuch as…\"]\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "words = vectorizer.get_feature_names()\n",
    "print(f\"#words {len(words)} {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector for first tweet\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"vector for first tweet\\n{X.toarray()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_BITS = 64\n",
    "\n",
    "def calculate_simhash(features_extracted, weights):\n",
    "    arrayvector_v = np.zeros(F_BITS)\n",
    "    \n",
    "    for feature, weight in zip(features_extracted, weights):\n",
    "        hash_of_feature = hash(feature)        \n",
    "        hash_to_binary = bin(ctypes.c_size_t(hash_of_feature).value)[2:]\n",
    "        hash_to_binary = hash_to_binary.zfill(F_BITS)\n",
    "        \n",
    "        for i, bit in enumerate(hash_to_binary):\n",
    "            if bit == '1':\n",
    "                arrayvector_v[i] += weight\n",
    "            else:\n",
    "                arrayvector_v[i] -= weight\n",
    "    \n",
    "    simhash_fingerprint = ''.join(['1' if v >= 0 else '0' for v in arrayvector_v])\n",
    "    \n",
    "    return simhash_fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#words 127 ['10', '19', '2021', '668', '9bhydkxz8u', 'ability', 'actual', 'admitted', 'advantage', 'aff', 'africa', 'airway', 'allisonpearson', 'anothe', 'antiviral', 'application', 'aren', 'asterhealthcare', 'babies', 'breakthrough', 'cases', 'caused', 'child', 'cihr', 'cihr_irsc', 'closing', 'continue', 'corrected', 'course', 'covid', 'covid19', 'cross', 'data', 'deis85208721', 'delta', 'did', 'die', 'disruptions', 'drcchambers', 'drmroz', 'edfuw5qjah', 'effect', 'enemyinastate', 'enhance', 'erictopol', 'evade', 'evades', 'extending', 'eyes', 'fail', 'far', 'freethinkfacts', 'going', 'hav', 'high', 'https', 'hyper', 'immune', 'immunity', 'impact', 'inasmuch', 'induced', 'infection', 'ivermectin', 'japan', 'kowa', 'light', 'load', 'london', 'lsoril', 'manifest', 'maxdkozlov', 'mdfacep', 'melulater', 'milde', 'mkky24weqv', 'mutations', 'nabs', 'november', 'older', 'omicron', 'people', 'peterandann', 'pompey1977', 'prevent', 'produced', 'protection', 'quicker', 'recent', 'registration', 'reinfection', 'related', 'reported', 'research', 'results', 'review', 'rt', 'says', 'sealsoftheend', 'showed', 'shown', 'south', 'spreads', 'stevebennett15', 'studies', 'sufficient', 'suggest', 'surge', 'svictor70973566', 'taken', 'thinks', 'toddlers', 'transmissible', 'upper', 'vaccine', 'vaccines', 'variant', 'veoqyz5x6f', 'versa', 'vice', 'viral', 'want', 'wasohope', 'widespread', 'wildantlers', 'working', 'yaneerbaryam']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"DrCChambers RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"sealsoftheend Japan's Kowa says Ivermectin showed 'antiviral effect' against Omicron https://t.co/mKKY24WeQV\",\n",
    "\"SVictor70973566 RT @EricTopol: Why is Omicron so hyper-transmissible? It's not related to high viral load in the upper airway, as shown by 2 recent studies…\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Actual cases of reinfection by Omicron are so widespread they are manifest to anyone who is not closing their eyes: 10/…\",\n",
    "\"lsoril RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"pompey1977 RT @AllisonPearson: How can people not get it? Omicron’s advantage over Delta is it evades the vaccine. Everyone is going to get Omicron…\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Taken together, our results suggest that Omicron-induced immunity may not be sufficient to prevent infection from anothe…\",\n",
    "\"SteveBennett15 RT @EricTopol: Anyone who thinks that vaccines aren't working against Omicron might want to review the data https://t.co/9bHYdKxz8u https:/…\",\n",
    "\"wasohope RT @ASTERHealthcare: Omicron covid-19 variant was reported from South Africa on November 2021. This variant has had many mutations that aff…\",\n",
    "\"SVictor70973566 RT @MdFacep: @EricTopol @maxdkozlov Omicron's impact is in its ability to evade our immune system: Our 'older' vaccine produced NABS fail…\",\n",
    "\"Wildantlers @melulater Of course it did, Omicron spreads far quicker. But as a % of people who die from omicron it is far milde… https://t.co/eDFuW5qjAH\",\n",
    "\"peterandann RT @EnemyInAState: Omicron, London: Babies and toddlers continue to surge, and 1 in 9 admitted is a child. Over 668 babies and toddlers hav…\",\n",
    "\"DrMroz RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"Deis85208721 CORRECTED-Japan's Kowa says ivermectin showed 'antiviral effect' against Omicron in research https://t.co/VEoQyz5x6F\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Thus, breakthrough infection from Omicron may enhance cross-protection against Delta, and vice-versa, [only] inasmuch as…\"]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "words = vectorizer.get_feature_names()\n",
    "print(f\"#words {len(words)} {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#words 28 ['antiviral', 'application', 'caused', 'cihr', 'cihr_irsc', 'covid19', 'delta', 'disruptions', 'effect', 'erictopol', 'extending', 'freethinkfacts', 'https', 'infection', 'ivermectin', 'japan', 'kowa', 'light', 'omicron', 'people', 'registration', 'rt', 'says', 'showed', 'svictor70973566', 'vaccine', 'variant', 'yaneerbaryam']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', min_df=2)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "words = vectorizer.get_feature_names()\n",
    "print(f\"#words {len(words)} {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "simhashes = []\n",
    "for i in range(len(corpus)):\n",
    "    features = vectorizer.get_feature_names()\n",
    "    weights = X[i].toarray()[0]\n",
    "    fingerprint = calculate_simhash(features, weights)\n",
    "    simhashes.append(fingerprint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Distances:\n",
      "[[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "calculate_hammingdistances = np.zeros((len(corpus), len(corpus)))\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(i + 1, len(corpus)):\n",
    "        calculate_hammingdistances[i, j] = hamming(simhashes[i], simhashes[j])\n",
    "              \n",
    "print(\"Hamming Distances:\")\n",
    "print(calculate_hammingdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Euclidean Distances:\n",
      "[[0.         4.35889894 3.46410162 3.46410162 0.         3.74165739\n",
      "  3.60555128 3.87298335 3.16227766 3.60555128 3.74165739 3.16227766\n",
      "  0.         4.35889894 3.74165739]\n",
      " [0.         0.         3.31662479 3.31662479 4.35889894 3.60555128\n",
      "  3.46410162 3.16227766 3.60555128 3.46410162 3.         3.\n",
      "  4.35889894 0.         3.60555128]\n",
      " [0.         0.         0.         2.         3.46410162 2.44948974\n",
      "  2.23606798 2.23606798 2.44948974 1.         2.44948974 1.41421356\n",
      "  3.46410162 3.31662479 2.44948974]\n",
      " [0.         0.         0.         0.         3.46410162 2.44948974\n",
      "  1.         2.64575131 2.44948974 2.23606798 2.44948974 1.41421356\n",
      "  3.46410162 3.31662479 1.41421356]\n",
      " [0.         0.         0.         0.         0.         3.74165739\n",
      "  3.60555128 3.87298335 3.16227766 3.60555128 3.74165739 3.16227766\n",
      "  0.         4.35889894 3.74165739]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  2.64575131 3.         2.82842712 2.23606798 2.         2.\n",
      "  3.74165739 3.60555128 2.44948974]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         2.82842712 2.64575131 2.44948974 2.64575131 1.73205081\n",
      "  3.60555128 3.46410162 1.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         3.         2.44948974 2.23606798 2.23606798\n",
      "  3.87298335 3.16227766 3.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         2.64575131 2.82842712 2.\n",
      "  3.16227766 3.60555128 2.82842712]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         2.64575131 1.73205081\n",
      "  3.60555128 3.46410162 2.64575131]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         2.\n",
      "  3.74165739 3.         2.82842712]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  3.16227766 3.         2.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         4.35889894 3.74165739]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         3.60555128]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "calculate_euclideandistances = np.zeros((len(corpus), len(corpus)))\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(i + 1, len(corpus)):\n",
    "        dist = euclidean(X[i].toarray()[0], X[j].toarray()[0])\n",
    "        calculate_euclideandistances[i, j] = dist\n",
    "\n",
    "print(\"\\nEuclidean Distances:\")\n",
    "print(calculate_euclideandistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pearson Correlation between Distances: 0.9432267784025823\n"
     ]
    }
   ],
   "source": [
    "correlation, _ = pearsonr(calculate_hammingdistances.flatten(), calculate_euclideandistances.flatten())\n",
    "print(\"\\nPearson Correlation between Distances:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#words 22 ['antiviral effect', 'caused omicron', 'cihr extending', 'cihr_irsc light', 'covid19 cihr', 'disruptions caused', 'effect omicron', 'extending registration', 'freethinkfacts rt', 'ivermectin showed', 'japan kowa', 'kowa says', 'light disruptions', 'omicron variant', 'registration application', 'rt cihr_irsc', 'rt erictopol', 'rt yaneerbaryam', 'says ivermectin', 'showed antiviral', 'svictor70973566 rt', 'variant covid19']\n",
      "[[0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"DrCChambers RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"sealsoftheend Japan's Kowa says Ivermectin showed 'antiviral effect' against Omicron https://t.co/mKKY24WeQV\",\n",
    "\"SVictor70973566 RT @EricTopol: Why is Omicron so hyper-transmissible? It's not related to high viral load in the upper airway, as shown by 2 recent studies…\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Actual cases of reinfection by Omicron are so widespread they are manifest to anyone who is not closing their eyes: 10/…\",\n",
    "\"lsoril RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"pompey1977 RT @AllisonPearson: How can people not get it? Omicron’s advantage over Delta is it evades the vaccine. Everyone is going to get Omicron…\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Taken together, our results suggest that Omicron-induced immunity may not be sufficient to prevent infection from anothe…\",\n",
    "\"SteveBennett15 RT @EricTopol: Anyone who thinks that vaccines aren't working against Omicron might want to review the data https://t.co/9bHYdKxz8u https:/…\",\n",
    "\"wasohope RT @ASTERHealthcare: Omicron covid-19 variant was reported from South Africa on November 2021. This variant has had many mutations that aff…\",\n",
    "\"SVictor70973566 RT @MdFacep: @EricTopol @maxdkozlov Omicron's impact is in its ability to evade our immune system: Our 'older' vaccine produced NABS fail…\",\n",
    "\"Wildantlers @melulater Of course it did, Omicron spreads far quicker. But as a % of people who die from omicron it is far milde… https://t.co/eDFuW5qjAH\",\n",
    "\"peterandann RT @EnemyInAState: Omicron, London: Babies and toddlers continue to surge, and 1 in 9 admitted is a child. Over 668 babies and toddlers hav…\",\n",
    "\"DrMroz RT @CIHR_IRSC: In light of the disruptions caused by the Omicron variant of #Covid19, CIHR is extending the registration and application de…\",\n",
    "\"Deis85208721 CORRECTED-Japan's Kowa says ivermectin showed 'antiviral effect' against Omicron in research https://t.co/VEoQyz5x6F\",\n",
    "\"freethinkfacts RT @yaneerbaryam: Thus, breakthrough infection from Omicron may enhance cross-protection against Delta, and vice-versa, [only] inasmuch as…\"]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', ngram_range=(2, 2), min_df=2)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "words = vectorizer.get_feature_names()\n",
    "print(f\"#words {len(words)} {words}\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Distances:\n",
      "[[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "simhashes = []\n",
    "for i in range(len(corpus)):\n",
    "    features = vectorizer.get_feature_names()\n",
    "    weights = X[i].toarray()[0]\n",
    "    fingerprint = calculate_simhash(features, weights)\n",
    "    simhashes.append(fingerprint)\n",
    "\n",
    "\n",
    "calculate_hammingdistances = np.zeros((len(corpus), len(corpus)))\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(i + 1, len(corpus)):\n",
    "        calculate_hammingdistances[i, j] = hamming(simhashes[i], simhashes[j])\n",
    "              \n",
    "print(\"Hamming Distances:\")\n",
    "print(calculate_hammingdistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Euclidean Distances:\n",
      "[[0.         4.24264069 3.60555128 3.60555128 0.         3.31662479\n",
      "  3.60555128 3.46410162 3.31662479 3.46410162 3.31662479 3.31662479\n",
      "  0.         4.24264069 3.60555128]\n",
      " [0.         0.         3.         3.         4.24264069 2.64575131\n",
      "  3.         2.82842712 2.64575131 2.82842712 2.64575131 2.64575131\n",
      "  4.24264069 0.         3.        ]\n",
      " [0.         0.         0.         2.         3.60555128 1.41421356\n",
      "  2.         1.         1.41421356 1.         1.41421356 1.41421356\n",
      "  3.60555128 3.         2.        ]\n",
      " [0.         0.         0.         0.         3.60555128 1.41421356\n",
      "  0.         1.73205081 1.41421356 1.73205081 1.41421356 1.41421356\n",
      "  3.60555128 3.         0.        ]\n",
      " [0.         0.         0.         0.         0.         3.31662479\n",
      "  3.60555128 3.46410162 3.31662479 3.46410162 3.31662479 3.31662479\n",
      "  0.         4.24264069 3.60555128]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.41421356 1.         0.         1.         0.         0.\n",
      "  3.31662479 2.64575131 1.41421356]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.73205081 1.41421356 1.73205081 1.41421356 1.41421356\n",
      "  3.60555128 3.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         1.41421356 1.         1.\n",
      "  3.46410162 2.82842712 1.73205081]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  3.31662479 2.64575131 1.41421356]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         1.\n",
      "  3.46410162 2.82842712 1.73205081]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  3.31662479 2.64575131 1.41421356]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  3.31662479 2.64575131 1.41421356]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         4.24264069 3.60555128]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         3.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "calculate_euclideandistances = np.zeros((len(corpus), len(corpus)))\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    for j in range(i + 1, len(corpus)):\n",
    "        dist = euclidean(X[i].toarray()[0], X[j].toarray()[0])\n",
    "        calculate_euclideandistances[i, j] = dist\n",
    "\n",
    "print(\"\\nEuclidean Distances:\")\n",
    "print(calculate_euclideandistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pearson Correlation between Distances: 0.8886480198878762\n"
     ]
    }
   ],
   "source": [
    "correlation, _ = pearsonr(calculate_hammingdistances.flatten(), calculate_euclideandistances.flatten())\n",
    "print(\"\\nPearson Correlation between Distances:\", correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
